{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uHQC2wNc7aEe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "CNVkzkHcEBRM",
        "outputId": "ad78f3bf-5f7b-4746-8941-89f6359215d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/1002.</td>\n",
              "      <td>Message-ID: &lt;30965995.1075863688265.JavaMail.e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       file                                            message\n",
              "0    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
              "1  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
              "2  allen-p/_sent_mail/1002.  Message-ID: <30965995.1075863688265.JavaMail.e..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emails = pd.read_csv('./enron.csv', skiprows=lambda x:x%2)\n",
        "# >>> this file is too big(around 0.5M rows) and take much time in our analysis\n",
        "# so if you are beginner then only extract half of data using given skiprows parameter\n",
        "emails.shape\n",
        "cols = emails.columns\n",
        "emails.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omrs_iL6EBqd",
        "outputId": "f5842104-2d6d-4957-ea90-e29e16e357d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Message-ID', '<15464986.1075855378456.JavaMail.evans@thyme>'),\n",
              " ('Date', 'Fri, 4 May 2001 13:51:00 -0700 (PDT)'),\n",
              " ('From', 'phillip.allen@enron.com'),\n",
              " ('To', 'john.lavorato@enron.com'),\n",
              " ('Subject', 'Re:'),\n",
              " ('Mime-Version', '1.0'),\n",
              " ('Content-Type', 'text/plain; charset=us-ascii'),\n",
              " ('Content-Transfer-Encoding', '7bit'),\n",
              " ('X-From', 'Phillip K Allen'),\n",
              " ('X-To', 'John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>'),\n",
              " ('X-cc', ''),\n",
              " ('X-bcc', ''),\n",
              " ('X-Folder', \"\\\\Phillip_Allen_Jan2002_1\\\\Allen, Phillip K.\\\\'Sent Mail\"),\n",
              " ('X-Origin', 'Allen-P'),\n",
              " ('X-FileName', 'pallen (Non-Privileged).pst')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import email\n",
        "message = emails.loc[0][\"message\"]\n",
        "e = email.message_from_string(message)\n",
        "e.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "K68S8QgqIqqd",
        "outputId": "bb722541-4a59-44d7-b963-99aa15d7ed13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "e.get_payload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gPr83cPEM3WH"
      },
      "outputs": [],
      "source": [
        "def get_field(field, messages):\n",
        "    column = []\n",
        "    for message in messages:\n",
        "        e = email.message_from_string(message)\n",
        "        column.append(e.get(field))\n",
        "    return column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "F-mv92mwM8cN",
        "outputId": "553e46f9-0908-48d5-c872-743a61e4a782"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "      <th>date</th>\n",
              "      <th>subject</th>\n",
              "      <th>X-Folder</th>\n",
              "      <th>X-From</th>\n",
              "      <th>X-To</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
              "      <td>Re:</td>\n",
              "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Randall L Gay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/1002.</td>\n",
              "      <td>Message-ID: &lt;30965995.1075863688265.JavaMail.e...</td>\n",
              "      <td>Thu, 31 Aug 2000 04:17:00 -0700 (PDT)</td>\n",
              "      <td>Re: Hello</td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Greg Piper</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       file  \\\n",
              "0    allen-p/_sent_mail/10.   \n",
              "1  allen-p/_sent_mail/1000.   \n",
              "2  allen-p/_sent_mail/1002.   \n",
              "\n",
              "                                             message  \\\n",
              "0  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
              "1  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
              "2  Message-ID: <30965995.1075863688265.JavaMail.e...   \n",
              "\n",
              "                                    date    subject  \\\n",
              "0   Fri, 4 May 2001 13:51:00 -0700 (PDT)        Re:   \n",
              "1  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)              \n",
              "2  Thu, 31 Aug 2000 04:17:00 -0700 (PDT)  Re: Hello   \n",
              "\n",
              "                                            X-Folder           X-From  \\\n",
              "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Phillip K Allen   \n",
              "1    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Phillip K Allen   \n",
              "2    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Phillip K Allen   \n",
              "\n",
              "                                                X-To  \n",
              "0  John J Lavorato <John J Lavorato/ENRON@enronXg...  \n",
              "1                                      Randall L Gay  \n",
              "2                                         Greg Piper  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emails[\"date\"] = get_field(\"Date\", emails[\"message\"])\n",
        "emails[\"subject\"] = get_field(\"Subject\", emails[\"message\"])\n",
        "emails[\"X-Folder\"] = get_field(\"X-Folder\", emails[\"message\"])\n",
        "emails[\"X-From\"] = get_field(\"X-From\", emails[\"message\"])\n",
        "emails[\"X-To\"] = get_field(\"X-To\", emails[\"message\"])\n",
        "emails.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "2So-6h8dNz9c",
        "outputId": "22983b9d-ec06-40a6-8279-4cc10ccd025c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "      <th>date</th>\n",
              "      <th>subject</th>\n",
              "      <th>X-Folder</th>\n",
              "      <th>X-From</th>\n",
              "      <th>X-To</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
              "      <td>Re:</td>\n",
              "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
              "      <td>Traveling to have a business meeting takes the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Randall L Gay</td>\n",
              "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/1002.</td>\n",
              "      <td>Message-ID: &lt;30965995.1075863688265.JavaMail.e...</td>\n",
              "      <td>Thu, 31 Aug 2000 04:17:00 -0700 (PDT)</td>\n",
              "      <td>Re: Hello</td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Greg Piper</td>\n",
              "      <td>Greg,\\n\\n How about either next Tuesday or Thu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       file  \\\n",
              "0    allen-p/_sent_mail/10.   \n",
              "1  allen-p/_sent_mail/1000.   \n",
              "2  allen-p/_sent_mail/1002.   \n",
              "\n",
              "                                             message  \\\n",
              "0  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
              "1  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
              "2  Message-ID: <30965995.1075863688265.JavaMail.e...   \n",
              "\n",
              "                                    date    subject  \\\n",
              "0   Fri, 4 May 2001 13:51:00 -0700 (PDT)        Re:   \n",
              "1  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)              \n",
              "2  Thu, 31 Aug 2000 04:17:00 -0700 (PDT)  Re: Hello   \n",
              "\n",
              "                                            X-Folder           X-From  \\\n",
              "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Phillip K Allen   \n",
              "1    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Phillip K Allen   \n",
              "2    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Phillip K Allen   \n",
              "\n",
              "                                                X-To  \\\n",
              "0  John J Lavorato <John J Lavorato/ENRON@enronXg...   \n",
              "1                                      Randall L Gay   \n",
              "2                                         Greg Piper   \n",
              "\n",
              "                                                body  \n",
              "0  Traveling to have a business meeting takes the...  \n",
              "1  Randy,\\n\\n Can you send me a schedule of the s...  \n",
              "2  Greg,\\n\\n How about either next Tuesday or Thu...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def body(messages):\n",
        "    column = []\n",
        "    for message in messages:\n",
        "        e = email.message_from_string(message)\n",
        "        column.append(e.get_payload())\n",
        "    return column\n",
        "\n",
        "emails[\"body\"] = body(emails[\"message\"])\n",
        "emails.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJLWalZGWY3C"
      },
      "source": [
        "# **Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edv-iV39N0Av",
        "outputId": "f23134a1-d886-4963-aca3-0cdaf7a26a6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16503"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mail_body = emails[(emails['body'].str.len() <100) & ~(emails['subject'].str.contains('Re:'))]\n",
        "\n",
        "len(mail_body['body'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adSD-c_TNfV",
        "outputId": "7ada36d9-c343-48d1-adc5-5b17b49de2c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21         Jeff,\\n\\n What is up with Burnet?\\n\\nPhillip\n",
              "24    http://www.hearme.com/vc2/?chnlOwnr=pallen@enr...\n",
              "39    Brenda\\n\\n Can you send me your address in Col...\n",
              "59    Hunter,\\n\\nAre you watching Alberto?  Do you h...\n",
              "64    Here is the 1st draft of a wish list for syste...\n",
              "Name: body, dtype: object"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mail_body['body'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eLV8wp426eYX"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/a/47091490/4084039\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KzkNCIIanCU1"
      },
      "outputs": [],
      "source": [
        "def preprocess_txt(data):\n",
        "    preprocessed = []\n",
        "    for sentance in data:\n",
        "        sent = decontracted(sentance)\n",
        "        sent = sent.replace('\\\\r', ' ')\n",
        "        sent = sent.replace('\\\\\"', ' ')\n",
        "        sent = sent.replace('\\\\n', ' ')\n",
        "        sent = sent.replace('^\\d+\\s|\\s\\d+\\s|\\s\\d+$', ' ')\n",
        "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "        sent = re.sub('http[s]?://\\S+', '', sent)\n",
        "        preprocessed.append(sent.lower().strip())\n",
        "    return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXn4P0NQoIqK",
        "outputId": "264625f0-a14d-4fc7-c0ed-6c106c75e4d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/4t/lgprytm509qfwrz2ttn2k1qc0000gn/T/ipykernel_78470/4290265588.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  mail_body['preprocessed_body']=preprocess_txt(mail_body['body'])\n"
          ]
        }
      ],
      "source": [
        "mail_body['preprocessed_body']=preprocess_txt(mail_body['body'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rtInk1Jonct",
        "outputId": "7ffc6476-f08b-4b23-b234-20137bcde746"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/4t/lgprytm509qfwrz2ttn2k1qc0000gn/T/ipykernel_78470/2365055629.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  mail_body['preprocessed_body']=mail_body['preprocessed_body'].str.replace('\\d+', '')\n",
            "/var/folders/4t/lgprytm509qfwrz2ttn2k1qc0000gn/T/ipykernel_78470/2365055629.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  mail_body['preprocessed_body']=mail_body['preprocessed_body'].str.replace('\\d+', '')\n"
          ]
        }
      ],
      "source": [
        "mail_body['preprocessed_body'] = mail_body['preprocessed_body'].str.replace('\\d+', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oquZq0Veq6mP"
      },
      "outputs": [],
      "source": [
        "def create_dataset(data):\n",
        "  final_op=[]\n",
        "  for row in data:\n",
        "      sentence = row\n",
        "      for i in range(1,len(sentence)):\n",
        "        sen=[]\n",
        "        p1 = 'cls '+ sentence[:i+1] + ' sep'\n",
        "        p2 = 'cls '+ sentence[i+1:] + ' sep'\n",
        "        sen.append(p1)\n",
        "        sen.append(p2)\n",
        "        final_op.append(sen)\n",
        "  final_df = pd.DataFrame(final_op, columns=['initial_text','suggestion'])\n",
        "  return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ro_-9NqUsYDY"
      },
      "outputs": [],
      "source": [
        "final_df=create_dataset(mail_body['preprocessed_body'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPH2Qi1Et0xH",
        "outputId": "2ef0687a-7ddf-48f4-c91f-918622a4de4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "initial_text    770585\n",
              "suggestion      770585\n",
              "dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "p0LCihXV2g2H"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv('./out/enron_processed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YJ4tHwgVQTdl",
        "outputId": "c614ce1f-d763-463e-8303-80c9d8d8d31b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>initial_text</th>\n",
              "      <th>suggestion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>cls je sep</td>\n",
              "      <td>cls ff what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>cls jef sep</td>\n",
              "      <td>cls f what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>cls jeff sep</td>\n",
              "      <td>cls  what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>cls jeff  sep</td>\n",
              "      <td>cls what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>cls jeff w sep</td>\n",
              "      <td>cls hat is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    initial_text                                 suggestion\n",
              "0           0      cls je sep  cls ff what is up with burnet phillip sep\n",
              "1           1     cls jef sep   cls f what is up with burnet phillip sep\n",
              "2           2    cls jeff sep    cls  what is up with burnet phillip sep\n",
              "3           3   cls jeff  sep     cls what is up with burnet phillip sep\n",
              "4           4  cls jeff w sep      cls hat is up with burnet phillip sep"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df=pd.read_csv('./out/enron_processed.csv')\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "0sZh86rrWg8F",
        "outputId": "e6babce9-00e8-4a23-a37f-81da0aa619d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>initial_text</th>\n",
              "      <th>suggestion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cls je sep</td>\n",
              "      <td>cls ff what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cls jef sep</td>\n",
              "      <td>cls f what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cls jeff sep</td>\n",
              "      <td>cls  what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cls jeff  sep</td>\n",
              "      <td>cls what is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cls jeff w sep</td>\n",
              "      <td>cls hat is up with burnet phillip sep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     initial_text                                 suggestion\n",
              "0      cls je sep  cls ff what is up with burnet phillip sep\n",
              "1     cls jef sep   cls f what is up with burnet phillip sep\n",
              "2    cls jeff sep    cls  what is up with burnet phillip sep\n",
              "3   cls jeff  sep     cls what is up with burnet phillip sep\n",
              "4  cls jeff w sep      cls hat is up with burnet phillip sep"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df.drop(columns='Unnamed: 0',inplace=True)\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GctymcI9Zkg",
        "outputId": "f5f40534-a80d-49be-cb02-58c28df56cdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "initial_text    0.0\n",
              "suggestion      0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(final_df.isnull().sum()/final_df.shape[0])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PtskxBrJXcTZ"
      },
      "outputs": [],
      "source": [
        "final_df=final_df[:30001]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Icut7HxYAHJ"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrtFFWAKOH_X",
        "outputId": "e9d4bb6c-1120-4c10-e133-f810240f8404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.11.2 in /Users/mvshmakov/.local/share/.pyenv/versions/3.8.12/lib/python3.8/site-packages (0.11.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /Users/mvshmakov/.local/share/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow-addons==0.11.2) (2.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py0ojCqeOAwE",
        "outputId": "a4b0238d-216c-4673-fb14-dacf377d09d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mvshmakov/.local/share/.pyenv/versions/3.8.12/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XhKAxn1wSNR8"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 32000\n",
        "BATCH_SIZE = 64\n",
        "# Let's limit the #training examples for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "I-vwdjpvYGTv"
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):        \n",
        "        # print(len(lang), \"example sentence: {}\".format(lang[0]))\n",
        "        lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>')\n",
        "        lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "        ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n",
        "        ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n",
        "        tensor = lang_tokenizer.texts_to_sequences(lang) \n",
        "\n",
        "        ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n",
        "        ## and pads the sequences to match the longest sequences in the given input\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "        return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XHWYq6KXYGWo"
      },
      "outputs": [],
      "source": [
        " def load_dataset(inp_lang,targ_lang):\n",
        "        # creating cleaned input, output pairs\n",
        "        #targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "        input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "        target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "        return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EZo7STymMBkz"
      },
      "outputs": [],
      "source": [
        "input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer=load_dataset(final_df.initial_text, final_df.suggestion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XV_blggyZkCv"
      },
      "outputs": [],
      "source": [
        " def call(input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer, BATCH_SIZE):\n",
        "        \n",
        "        input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "        train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "        val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "        \n",
        "        return input_tensor_train, target_tensor_train,input_tensor_val, target_tensor_val,train_dataset, val_dataset, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t3HB3H0lM9j-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-30 13:58:32.153695: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "input_tensor_train, target_tensor_train,input_tensor_val, target_tensor_val,train_dataset, val_dataset, inp_lang_tokenizer, targ_lang_tokenizer=call(input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer,BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LMMdAdjOoJT",
        "outputId": "dbbe1493-326b-4de5-d2fe-99f89eaf355d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([64, 23]), TensorShape([64, 23]))"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Y_qXE00FOoMu"
      },
      "outputs": [],
      "source": [
        "vocab_inp_size = len(final_df.initial_text)+1\n",
        "vocab_tar_size = len(final_df.suggestion)+1\n",
        "max_length_input = example_input_batch.shape[1]\n",
        "max_length_output = example_target_batch.shape[1]\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS2WLh28OoPC",
        "outputId": "166e02dc-7dd6-446d-8dbe-278b5f7589b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_length_input, max_length_output, vocab_inp_size, vocab_tar_size\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(23, 23, 30002, 30002)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"max_length_input, max_length_output, vocab_inp_size, vocab_tar_size\")\n",
        "max_length_input, max_length_output, vocab_inp_size, vocab_tar_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yT5yKQaYArgR"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('./out/train.pickle', 'wb') as f:\n",
        "    pickle.dump([input_tensor_train, target_tensor_train,input_tensor_val, target_tensor_val, inp_lang_tokenizer, targ_lang_tokenizer, vocab_inp_size, vocab_tar_size, max_length_input, max_length_output, vocab_inp_size, vocab_tar_size], f)#,train_dataset, val_dataset, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bOQt8qovQmHk"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 10)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/4t/lgprytm509qfwrz2ttn2k1qc0000gn/T/ipykernel_78470/3334373199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./out/train.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_tensor_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_inp_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_tar_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_inp_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_tar_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 10)"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open('./out/train.pickle', 'rb') as f:\n",
        "    input_tensor_train, target_tensor_train, input_tensor_val, target_tensor_val, vocab_inp_size, vocab_tar_size, max_length_input, max_length_output, vocab_inp_size, vocab_tar_size = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZGmIwhyYG62"
      },
      "source": [
        "# **Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "aVN0t4iYUjFd"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    ##-------- LSTM layer in Encoder ------- ##\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, h, c = self.lstm_layer(x, initial_state = hidden)\n",
        "    return output, h, c\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA6sLEexYNSd",
        "outputId": "c45ff7a0-ef5a-4041-dda1-fcee2da18f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 23, 1024)\n",
            "Encoder h vecotr shape: (batch size, units) (64, 1024)\n",
            "Encoder c vector shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "## Test Encoder Stack\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
        "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Tp_8f7_oYNVf"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_type='luong'):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.attention_type = attention_type\n",
        "    \n",
        "    # Embedding Layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    \n",
        "    #Final Dense layer on which softmax will be applied\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # Define the fundamental cell for decoder recurrent structure\n",
        "    self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
        "   \n",
        "\n",
        "\n",
        "    # Sampler\n",
        "    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "    # Create attention mechanism with memory = None\n",
        "    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \n",
        "                                                              None, self.batch_sz*[max_length_input], self.attention_type)\n",
        "\n",
        "    # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
        "    self.rnn_cell = self.build_rnn_cell(batch_sz)\n",
        "\n",
        "    # Define the decoder with respect to fundamental rnn cell\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
        "\n",
        "    \n",
        "  def build_rnn_cell(self, batch_sz):\n",
        "    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n",
        "                                  self.attention_mechanism, attention_layer_size=self.dec_units)\n",
        "    return rnn_cell\n",
        "\n",
        "  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
        "    # ------------- #\n",
        "    # typ: Which sort of attention (Bahdanau, Luong)\n",
        "    # dec_units: final dimension of attention outputs \n",
        "    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
        "    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
        "\n",
        "    if(attention_type=='bahdanau'):\n",
        "      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
        "    else:\n",
        "      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
        "\n",
        "  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
        "    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
        "    return decoder_initial_state\n",
        "\n",
        "\n",
        "  def call(self, inputs, initial_state):\n",
        "    x = self.embedding(inputs)\n",
        "    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output-1])\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y12whlY1Toc5",
        "outputId": "e1c99935-f0b6-45a2-c204-ff9e26c82638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder Outputs Shape:  (64, 22, 30002)\n"
          ]
        }
      ],
      "source": [
        "# Test decoder stack\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 'luong')\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\n",
        "decoder.attention_mechanism.setup_memory(sample_output)\n",
        "initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_h, sample_c], tf.float32)\n",
        "\n",
        "\n",
        "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
        "\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hMUcFISbk6cv"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  # real shape = (BATCH_SIZE, max_length_output)\n",
        "  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fPCy8ShWqU4z"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "\n",
        "\n",
        "    dec_input = targ[ : , :-1 ] # Ignore <end> token\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\n",
        "\n",
        "    # Set the AttentionMechanism object with encoder_outputs\n",
        "    decoder.attention_mechanism.setup_memory(enc_output)\n",
        "\n",
        "    # Create AttentionWrapperState as initial_state for decoder\n",
        "    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
        "    pred = decoder(dec_input, decoder_initial_state)\n",
        "    logits = pred.rnn_output\n",
        "    loss = loss_function(real, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "AIDVkgyYapNu"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = 30000 // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThPE9V7fqX2L",
        "outputId": "43d60bf3-3e9e-4a68-d567-6151a84e6d82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-30 14:01:56.328632: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 9437184 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-11-30 14:01:56.387079: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 9437184 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.3828\n",
            "Epoch 1 Batch 100 Loss 1.6949\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    decoder.save_weights('./out/model_weights/{}_Loss_{:.4f}_decoder.h5'.format(epoch + 1,total_loss / steps_per_epoch))\n",
        "    encoder.save_weights('./out/model_weights/{}_Loss_{:.4f}_encoder.h5'.format(epoch + 1,total_loss / steps_per_epoch))\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwe8z0oyqdP6"
      },
      "outputs": [],
      "source": [
        "def evaluate_sentence(sentence):\n",
        "  sentence =sentence #dataset_creator.preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]#\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=max_length_input,\n",
        "                                                          padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  inference_batch_size = inputs.shape[0]\n",
        "  result = ''\n",
        "\n",
        "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "  dec_h = enc_h\n",
        "  dec_c = enc_c\n",
        "\n",
        "  start_tokens = tf.fill([inference_batch_size], targ_lang_tokenizer.word_index['cls'])\n",
        "  end_token = targ_lang_tokenizer.word_index['sep']\n",
        "\n",
        "  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "\n",
        "  # Instantiate BasicDecoder object\n",
        "  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n",
        "  # Setup Memory in decoder stack\n",
        "  decoder.attention_mechanism.setup_memory(enc_out)\n",
        "\n",
        "  # set decoder_initial_state\n",
        "  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
        "\n",
        "\n",
        "  ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
        "  ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
        "  ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
        "\n",
        "  decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "  \n",
        "  outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n",
        "  return outputs.sample_id.numpy()\n",
        "\n",
        "def translate(sentence):\n",
        "  result = evaluate_sentence(sentence)\n",
        "  #print(result)\n",
        "  result = targ_lang_tokenizer.sequences_to_texts(result)\n",
        "  #print('Input: %s' % (sentence))\n",
        "  print('Predicted Suggestion: {}'.format(str(result).replace(\" sep\",\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB9PWMxHhFhV",
        "outputId": "e8fa018c-48b4-4e9a-ae96-3853804a9357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Suggestion: ['jacques craig will draw up a release what is the status on the quote from wade phillip']\n"
          ]
        }
      ],
      "source": [
        "translate(u'cls jeff sep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYLPpLg69Nr9",
        "outputId": "32704f3c-24ec-40c1-93bc-13be9dd6c1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Text je\n",
            "Expected Suggestion ff what is up with burnet phillip\n",
            "Predicted Suggestion: ['ff i am in the office today any isssues to deal with for the stagecoach phillip']\n",
            "=============================================================\n",
            "Input Text jeff wh\n",
            "Expected Suggestion at is up with burnet phillip\n",
            "Predicted Suggestion: ['at is up with burnet phillip']\n",
            "=============================================================\n",
            "Input Text jeff what is\n",
            "Expected Suggestion  up with burnet phillip\n",
            "Predicted Suggestion: ['up with burnet phillip']\n",
            "=============================================================\n",
            "Input Text jeff what is up w\n",
            "Expected Suggestion ith burnet phillip\n",
            "Predicted Suggestion: ['ith burnet phillip']\n",
            "=============================================================\n",
            "Input Text jeff what is up with b\n",
            "Expected Suggestion urnet phillip\n",
            "Predicted Suggestion: ['urnet phillip']\n",
            "=============================================================\n",
            "Input Text jeff what is up with burnet\n",
            "Expected Suggestion  phillip\n",
            "Predicted Suggestion: ['phillip']\n",
            "=============================================================\n",
            "Input Text jeff what is up with burnet phil\n",
            "Expected Suggestion lip\n",
            "Predicted Suggestion: ['lip']\n",
            "=============================================================\n"
          ]
        }
      ],
      "source": [
        "for k in range(0,35,5):\n",
        "  print(\"Input Text\",final_df['initial_text'][k].replace(\"cls \",\"\").replace(\" sep\",\"\"))\n",
        "  print(\"Expected Suggestion\",final_df['suggestion'][k].replace(\"cls \",\"\").replace(\" sep\",\"\"))\n",
        "  translate(final_df['initial_text'][k])\n",
        "  print(\"=============================================================\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LKJQOw0V8HIr",
        "gQYPXpDDVQv9",
        "lBjLBU_hgJcZ",
        "fJLWalZGWY3C",
        "5Icut7HxYAHJ"
      ],
      "name": "Attention_Enron_autocomplete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
